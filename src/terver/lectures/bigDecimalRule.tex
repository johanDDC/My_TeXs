\section{Закон больших чисел.}

\subsection{Закон больших чисел в слабой форме.}
\begin{lemma}[Закон больших чисел в слабой форме]
    Пусть $\{X_n\}_n$ --- последовательность независимых одинаково распределённых случайных величин, и $\EE(X_n^2) < \infty$.
    Пусть $\EE(X_1) = m$, тогда $\forall\;\epsilon > 0$ верно
    \[
        \lim\limits_{n \to \infty} P\left( \left| \frac{\sum\limits_{k = 1}^n X_k}{n} - m \right| \geq \epsilon \right) = 0
    \]
\end{lemma}
\begin{proof}
    Т.к. все величины одинаково распределены и $\EE(X_1) = m$, то $\forall\; i\; \EE(X_i) = m$. Тогда
    \[
        \EE\left( \frac{\sum\limits_{k = 1}^n X_k}{n} \right) = \sum\limits_{k = 1}^n \EE\left( \frac{X_k}{n} \right) =
        n \cdot \frac{\EE(X_1)}{n} = m
    \]
    Тогда по \hyperref[ChebyshevCorollary]{следствию из неравенства Чебышева}:
    \[
        P\left( \left| \frac{\sum\limits_{k = 1}^n X_k}{n} - m \right| \geq \epsilon \right)
        \leq \frac{\DD\left(\frac{1}{n}\sum\limits_{k = 1}^n X_k\right)}{\epsilon^2} =
        \frac{\DD\left(\sum\limits_{k = 1}^n X_k\right)}{n^2\epsilon^2} =
        \frac{n\DD(X_1)}{n^2\epsilon^2} = \frac{\DD(X_1)}{n\epsilon^2}
    \]
    Устремляя $n$ к бесконечности получаем доказательство утверждения.
\end{proof}
\begin{comment}
    Пусть $X_k$ --- независимые бернулиевские случайные величины с вероятностью успеха $p$. Тогда величина
    $\frac{\sum\limits_{k = 1}^n X_k}{n}$ --- частота успешного исхода эксперимента при проведении $n$ независимых
    испытаний. Известно, что $\EE(X_k) = p$, тогда $\DD(X_k) = \EE(X_k^2) - \EE(X_k)^2 = p^2 - p = pq$, где $q = (1 - p)$.
    Тогда
    \[
        P\left( \left| \frac{\sum\limits_{k = 1}^n X_k}{n} - p \right| \geq \epsilon \right)
        \leq \frac{pq}{n\epsilon^2} \xrightarrow[n \to \infty]{} 0
    \]
    Т.е. при проведении большого числа испытаний, частота успешного результата эсперимента стремится к $p$.

    Можно разобрать смысл этого утверждения на примере: пусть эксперимент у нас состоит в подкидывании монеты, успехом
    мы считаем выпадение орла. Очевидно, что в одном независимом испытании орёл выпадает с вероятностью $\frac{1}{2}$.
    При этом в жизни подбрасывая монету $5, 10$ и даже $100$ раз мы можем ни разу не получить орла. Но данное утверждение
    говорит нам о том, что при проведении огромного числа испытаний, вероятность выпадения орла в среднем во всех испытаниях
    будет примерно $\frac{1}{2}$.
\end{comment}

\subsection{Теорема Муавра-Лапласа.}
Пусть $X_k$ --- независимые бернулиевские случайные величины с вероятностью успеха $p$. Пусть $S_n$ --- количество успешных испытаний
$\left( S_n = \sum\limits_{k = 1}^{n} X_k \right)$. $S_n$ имеет биномиальное распределение:
\[
    P(S_n = k) = \binom{n}{k}p^{k}q^{n - k}
\]
Исследуем поведение $P(S_n = k)$ при больших $n$.
\begin{theorem}[Муавра-Лапласа]
    Если $n \to \infty$, вероятность исхода $p \in (0, 1)$ фиксирована, величина $x_m = \frac{m - np}{\sqrt{npq}}$ ограничена
    равномерно по $m, n$ ($\exists\;a, b \in \RR \colon a \leq x_m \leq b$), то
    \[
        P(S_n = m) \sim \frac{1}{\sqrt{npq}}\phi(x_m), ~~~ \phi(x_m) = \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}
    \]
    где $\phi(x_m)$ --- \it{плотность стандарного нормального распределения} (что
    бы это ни значило).
\end{theorem}

\subsection{Задача о булочках с изюмом.}
\begin{problem}[О булочках с изюмом]
    Будем заниматься изготовлением булочек с изюмом в промышленных масштабах. Чтобы получить сколько-то готовых
    булочек, нужно закинуть все ингридиенты (тесто и изюм) в специальную машину, которая сама всё сделает и на
    выходе у нас будет готовый продукт. Под ''готовым продуктом`` понимается \textbf{готовый продукт}: после
    того как машина его выдаст, в нём ничего изменить не получится. Мы хотим выяснить, какое наименьшее число
    изюминок нужно добавить, чтобы с высокой вероятностью ($> 0.99$) в каждой булочке была бы хотя бы одна изюминка?

    \it{Решение:} Пусть мы собираемся изготовить $N$ булочек, и рассчитываем тратить не более $\lambda$
    изюма на булочку. Тогда всего нам потребуется засыпать $N\lambda$ изюма. Каждая изюминка попадает в
    конкретную булочку с вероятностью $\frac{1}{N}$ (т.к. каждая добавленная изюминка должна попасть хоть
    в какую-нибудь булочку). Соответственно, каждая изюминка не попадает в конкретную булочку с вероятностью
    $1 - \frac{1}{N}$. Тогда случайная величина $S$ --- количество изюминок, попавших в конкретную булочку, имеет
    биномиальное распределение, и событие ''в конкретную булочку не попала ни одна изюминка`` записывается как
    \[
        P(S = 0) = \left( 1 - \frac{1}{N} \right)^{N\lambda} = e^{-\lambda}
    \]
    Теперь остаётся только выбрать такое $\lambda$, чтобы вероятность такого непрятного события была менее $0.01$.
    Подойдёт $\lambda = 5$: $e^{-5} \approx 0,0067 < 0.01$.
\end{problem}

\subsection{Теорема Пуассона.}
\begin{theorem}
    Пусть проводится $N$ серии, в кажой серии ровно $N$ испытаний по схеме Бернулли.
    Пусть вероятность успеха в $N$-ой серии равна $p_N$, и известно, что
    $p_N \cdot N = \lambda$ (некий показатель среднего результата в каждой серии).
    Тогда вероятность наступления ровно $k$ успехов в $N$-ой серии равна
    \[
        P(S_N = k) \xrightarrow{N \to \infty} \frac{\lambda^k}{k!}e^{-\lambda}
    \]
\end{theorem}
\begin{proof}
    Если $p_N \cdot N = \lambda$, то $p_N = \frac{\lambda}{N}$. Тогда
    \begin{align*}
        P(S_N = k) &= \binom{N}{k}p_N^{k}(1 - p_N)^{N - k} = \frac{N!}{k!(N - k)!} \cdot
        \left( \frac{\lambda}{N} \right)^k \cdot \left( 1 - \frac{\lambda}{N} \right)^{N - k} =\\
        &= \frac{\lambda^k}{k!} \cdot \frac{N(N - 1) \cdot \ldots \cdot (N - k + 1)}{N^k}
        \cdot \underbrace{\left( 1 - \frac{\lambda}{N} \right)^{-k}}_{\to 1}
        \cdot \underbrace{\left( 1 - \frac{\lambda}{N} \right)^N}_{\to e^{-\lambda}} =\\
        &= \frac{\lambda^k}{k!}
        \cdot \underbrace{\left( 1 - \frac{1}{N} \right)}_{\to 1}
        \cdot \underbrace{\left( 1 - \frac{2}{N} \right)}_{\to 1}
        \cdot \ldots
        \cdot \underbrace{\left( 1 - \frac{k - 1}{N} \right)}_{\to 1}
        \cdot e^{-\lambda}
        =\frac{\lambda^k}{k!} e^{-\lambda}
    \end{align*}
\end{proof}
\subsection{Модель Эрдеша-Реньи случайного графа и надёжность сети.}
Пусть есть $n$ городов, причём каждый городо соединён дорогой с каждым другим. Известно, что за год конкретная
дорога приходит в негодность с вероятностью $1 - p$. Соответственно, конкретная дорога за год не изнашивается
с вероятностью $p$. Хотим узнать, с какой вероятностью через год из каждого города можно будет добраться до
всех остальных?
\begin{proposal}
    Пусть $V$ --- множество из $n$ вершин графа.
    Если $p = \frac{c\ln(n)}{n}$, и $c > 2$, то граф связен с вероятностью, стремящейся к единице.
\end{proposal}
\begin{proof}
    Пусть $X_n$ --- случайная величина, такая что
    \[
        X_n =
        \begin{cases}
            \text{число компонент связности} & \text{граф несвязен}\\
            0 & \text{граф связен}
        \end{cases}
    \]
    Покажем, что $P(X > 1) \to 0$: рассмотри все $k$-элементные подмножества множества наших вершин:
    $K^k_1, K^k_2, \ldots, K^k_{\binom{n}{k}}$, и рассмотрим события следующего вида: $A_{n, k, j}$ ---
    множество $K^k_j$ является компонентой связности. Тогда распишем случайную величину $X_n$:
    \[
        X_n = \sum\limits_{k = 1}^{n - 1} \sum\limits_{j = 1}^{\binom{n}{k}} I_{A_{n, k, j}}
    \]
    где $I_{A_{n, k, j}} = 1$, если $K^k_j$ --- компонента связности, и $0$ иначе. Оценим матожидание:
    \begin{align*}
        \EE(X_n) &= \sum\limits_{k = 1}^{n - 1} \sum\limits_{j = 1}^{\binom{n}{k}}
        \underbrace{\EE(I_{A_{n, k, j}})}_{P(A_{n, k, j})} \overset{(1)}{\leq}
        \sum\limits_{k = 1}^{n - 1} \sum\limits_{j = 1}^{\binom{n}{k}}
        P\left( K^k_j \text{ не соединён с } V \setminus K^k_j \right) \overset{(2)}{=}
        \sum\limits_{k = 1}^{n - 1} \binom{n}{k} q^{k(n - k)} =\\
        & = \sum\limits_{k = 1}^{\frac{n}{2}} \binom{n}{k} q^{k(n - k)} +
        \sum\limits_{k = \frac{n}{2} + 1}^{n - 1} \binom{n}{k} q^{k(n - k)} \overset{(3)}{=}
        2\sum\limits_{k = 1}^{\frac{n}{2}} \binom{n}{k} q^{k(n - k)} \overset{(4)}{\leq}
        2\sum\limits_{k = 1}^{\frac{n}{2}} \binom{n}{k} \left(q^{\frac{n}{2}}\right)^k \leq\\
        & \leq 2\sum\limits_{k = 1}^{n - 1} \binom{n}{k} \left(q^{\frac{n}{2}}\right)^k =
        \leq 2\sum\limits_{k = 1}^{n - 1} \binom{n}{k} (1^{n - k}) \left(q^{\frac{n}{2}}\right)^k
        = 2(1 + q^{\frac{n}{2}})^n - 2 - 2q^{\frac{n^2}{2}}
    \end{align*}
    Объяснение перехода (1): для события $A_{n, k, j}$ мы требуем, чтобы все вершины в множестве $K^k_j$
    были связаны между собой, и ни одна из них не была связана с $V \setminus K^k_j$. Переходя к событиям
    $\{ K^k_j \text{ не соединён с } V \setminus K^k_j \}$ мы отказываемся от первого требования, и получается,
    что события $A_{n, k, j}$ являются подмножествами в новых событиях, а значит, их вероятности оцениваются
    сверху.\\
    Объяснение перехода (2): Вероятность новых событий мы умеем считать: это просто значит, что между каждой
    из $k$ вершин нашего множества, и каждой из оставшихся $n - k$ вершин его дополнения отсутствует ребро
    (отсутствует дорога между городами). Для каждого ребра вероятность такого события равна $q$, и события
    независимы.\\
    Объяснение перехода (3):
    \[
        \sum\limits_{k = \frac{n}{2} + 1}^{n - 1} \binom{n}{k} q^{k(n - k)} =
        \sum\limits_{k = 1}^{\frac{n}{2}} \binom{n}{n - k} q^{(n - k)(n - (n - k))}
    \]
    Свойство числа сочетаний: $\binom{n}{k} = \binom{n}{n - k}$.\\
    Объяснение перехода (4): $k \leq \frac{n}{2} \implies n - k \geq \frac{n}{2} \implies
    q^{n - k} \leq q^{\frac{n}{2}}$. Последний переход верен т.к. $|q| \leq 1$.

    По условию $q = (1 - p) = \left( 1 - \frac{c\ln(n)}{n} \right) \implies q^{\frac{n}{2}} =
    \left( 1 - \frac{c\ln(n)}{n} \right)^{\frac{n}{2}} = e^{\frac{n}{2}\ln\left( 1 - \frac{c\ln(n)}{n} \right)}
    =e^{\frac{n}{2}\left( -\frac{c\ln(n)}{n} + O\left( \frac{\ln^2(n)}{n^2} \right) \right)} =\\
    =e^{\frac{c}{2}\ln(n) + o(1)} = e^{o(1)} \cdot n^{-\frac{c}{2}}$.\\
    Тогда теперь
    \[
        (1 + q^{\frac{n}{2}})^n = (1 + e^{o(1)} \cdot n^{-\frac{c}{2}})^n =
        e^{n\ln\left( 1 + e^{o(1)}n^{-\frac{c}{2}} \right)} =
        e^{n \cdot n^{-\frac{c}{2}}e^{o(1)} + o(1)}
    \]
    Понятно, что $\frac{c}{2} > 1$, поэтому $n^{-\frac{c}{2}} \to 0$, и поэтому всё выражение сходится к $1$.
    Тогда $2(1 + q^{\frac{n}{2}})^n - 2 - 2q^{\frac{n^2}{2}} \to 0 \iff \EE(X_n) \to 0$,
    и по неравенству Чебышева: $P(X_n > 1) \leq \EE(X_n) \to 0$.
\end{proof}